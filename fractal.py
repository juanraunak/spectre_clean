# agent4_skill_gap.py
# ---------------------------------------------------------------------
# Agent 4 â€” Unified Skill Gap Analyzer (consumes Mirage's matches)
# What it does:
#   1) Load normalized company skills (from Agent 3) + raw competitors
#   2) Merge records by name+company for quick lookup
#   3) Read spectre_matches.json (generated by Mirage / Agent 2)
#   4) Compute per-employee skill gaps vs matched competitors
#   5) (Optional) Use Azure OpenAI to write short reasoning blurbs
#   6) Export Step 1 + Step 2 JSON files
#
# Orchestration:
#   - async run(context) -> context
#   - run_sync(context)
#
# Differences vs your previous file:
#   - Removed internal SpectreMatcher (matching happens in Mirage)
#   - No hardcoded API keys (env or provided azure_config)
#   - Smaller surface area, better logging & guardrails
# ---------------------------------------------------------------------

import os
import re
import json
import asyncio
import logging
from dataclasses import dataclass
from typing import Dict, List, Any, Optional, Tuple, Set
from pathlib import Path

# Optional Azure OpenAI client (used only if configured)
try:
    from openai import AzureOpenAI
except Exception:
    AzureOpenAI = None  # handled gracefully at runtime

# ----------------------------
# Logging
# ----------------------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
log = logging.getLogger("agent4_skill_gap")


# ----------------------------
# Config (defaults; can be overridden via CLI or orchestrator context)
# ----------------------------
class Config:
    # Inputs
    SKILL_DIR = "company_skills"               # output of Agent 3
    RAW_DIR = "employee_data"                  # raw competitor reports
    SPECTRE_PATH = "spectre_matches.json"      # produced by Mirage

    # Outputs
    STEP1_DETAILED = "step1_missing_skills.json"
    STEP1_BASIC = "step1_missing_skills_basic.json"
    STEP2_DETAILED = "final_skill_gaps_detailed_gpt.json"
    OUTPUT_FILE = "final_skill_gaps.json"

    # Company focus
    SPECTRE_COMPANY = "Manipal Fintech"                 # primary company key (lowercase)

    # Analysis toggles
    USE_LLM_FOR_SKILLS = True                  # LLM for reasoning summaries
    LLM_TEMPERATURE = 0.1
    LLM_MAX_TOKENS = 200

    # Filters
    MAX_EMPLOYEES_TO_ANALYZE = None           # cap employees having matches
    MAX_SKILLS_TO_SHOW = None                 # cap skills in outputs (None=all)

    # Skill normalization
    CUSTOM_SKILL_ALIASES = {
        "ms excel": "excel",
        "microsoft excel": "excel",
        "power point": "powerpoint",
        "nlp": "natural language processing",
        "gen ai": "generative ai",
        "py": "python",
        "js": "javascript",
    }

    # Debug
    DEBUG_MODE = True
    SHOW_SAMPLE_OUTPUT = True

    @classmethod
    def validate(cls):
        if not cls.SPECTRE_COMPANY:
            raise ValueError("SPECTRE_COMPANY must be set")
        return True

    @classmethod
    def print_summary(cls):
        print("=== Agent 4 Config ===")
        print(f"Spectre company: {cls.SPECTRE_COMPANY}")
        print(f"Skills dir:      {cls.SKILL_DIR}")
        print(f"Raw dir:         {cls.RAW_DIR}")
        print(f"Matches path:    {cls.SPECTRE_PATH}")
        print(f"Use LLM:         {cls.USE_LLM_FOR_SKILLS}")
        print("======================")


# ----------------------------
# Data Loader
# ----------------------------


class DataLoader:
    def __init__(self, skill_dir: str, raw_dir: str):
        self.skill_dir = skill_dir
        self.raw_dir = raw_dir
        self.skills_by_company: Dict[str, Dict[str, List[str]]] = {}       # {company: {employee_id: [skills]}}
        self.skills_name_by_company: Dict[str, Dict[str, List[str]]] = {}  # {company: {normalized_name: [skills]}}
        self.raw_by_company: Dict[str, List[Dict[str, Any]]] = {}          # {company: [raw employee dicts]}

    @staticmethod
    def _load_json(path: str) -> Any:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)

    @staticmethod
    def _norm_name(s: str) -> str:
        return re.sub(r"[^a-z0-9]+", " ", (s or "").lower()).strip()

    @staticmethod
    def _normalize_company_name(name: Optional[str]) -> str:
        n = (name or "").strip().lower()
        # normalize spectre variants to the single key
        spectre = Config.SPECTRE_COMPANY.lower()
        variations = [spectre, f"{spectre} group", f"{spectre} technologies", f"{spectre} fintech"]
        for v in variations:
            if v in n:
                return spectre
        return n

    @staticmethod
    def _get(d: Any, path: str, default=None):
        cur = d
        for key in path.split("."):
            if not isinstance(cur, dict) or key not in cur:
                return default
            cur = cur[key]
        return cur

    def _extract_skills_company_employees(self, obj: Any) -> Tuple[str, List[Dict[str, Any]]]:
        """
        Supports shapes like:
          {"company_name": "...", "employees":[{"employee_id": "...", "name":"...", "skills":[...]}]}
          {"employees":[...]} with optional "company_name"
        """
        company = None
        employees: List[Dict[str, Any]] = []
        if isinstance(obj, dict):
            if "employees" in obj and isinstance(obj["employees"], list):
                employees = obj["employees"]
                company = obj.get("company_name") or obj.get("company")
            elif "data" in obj and isinstance(obj["data"], dict) and isinstance(obj["data"].get("employees"), list):
                employees = obj["data"]["employees"]
                company = obj["data"].get("company_name") or obj.get("company_name")
        elif isinstance(obj, list):
            employees = obj
        if not company and employees and isinstance(employees[0], dict):
            company = employees[0].get("company")
        return self._normalize_company_name(company or ""), employees

    def _extract_raw_company_employees(self, obj: Any) -> Tuple[str, List[Dict[str, Any]]]:
        """
        RAW shape:
          {
            "mission_metadata": { "target_company": "..." },
            "employee_intelligence": { "employees": [ ... ] }
          }
        """
        if not isinstance(obj, dict):
            return "", []
        employees = self._get(obj, "employee_intelligence.employees", []) or []
        company = self._get(obj, "mission_metadata.target_company")
        if not company and employees:
            company = (
                self._get(employees[0], "basic_info.company")
                or self._get(employees[0], "detailed_profile.current_company.name")
            )
        return self._normalize_company_name(company or ""), employees

    def load_skills(self):
        print("=== Load skills (Agent 3 output) ===")
        ids: Dict[str, Dict[str, List[str]]] = {}
        names: Dict[str, Dict[str, List[str]]] = {}

        if not os.path.isdir(self.skill_dir):
            print(f"âš ï¸  Skills directory missing: {self.skill_dir}")
            self.skills_by_company, self.skills_name_by_company = {}, {}
            return

        for fname in os.listdir(self.skill_dir):
            if not fname.endswith(".json"):
                continue
            try:
                obj = self._load_json(os.path.join(self.skill_dir, fname))
                company, employees = self._extract_skills_company_employees(obj)
                if not company:
                    if Config.DEBUG_MODE:
                        print(f"   âš ï¸ {fname}: could not determine company; skipping")
                    continue
                id_map: Dict[str, List[str]] = {}
                name_map: Dict[str, List[str]] = {}
                for e in employees:
                    skills = (e.get("skills") or [])
                    if Config.MAX_SKILLS_TO_SHOW and len(skills) > Config.MAX_SKILLS_TO_SHOW:
                        skills = skills[: Config.MAX_SKILLS_TO_SHOW]
                    emp_id = e.get("employee_id")
                    if emp_id is not None:
                        id_map[str(emp_id)] = skills
                    nm = self._norm_name(e.get("name", ""))
                    if nm:
                        # keep richer skill list if duplicate names
                        prior = name_map.get(nm, [])
                        name_map[nm] = skills if len(skills) >= len(prior) else prior
                ids[company] = id_map
                if name_map:
                    names[company] = name_map
                print(f"   loaded skills for '{company}': {len(id_map)} employees")
            except Exception as e:
                print(f"âŒ parse error {fname}: {e}")

        self.skills_by_company = ids
        self.skills_name_by_company = names

    def load_raw(self):
        print("\n=== Load raw competitor data ===")
        out: Dict[str, List[Dict[str, Any]]] = {}
        if not os.path.isdir(self.raw_dir):
            print(f"âš ï¸  Raw directory missing: {self.raw_dir}")
            self.raw_by_company = {}
            return

        for fname in os.listdir(self.raw_dir):
            if not fname.endswith(".json"):
                continue
            try:
                obj = self._load_json(os.path.join(self.raw_dir, fname))
                company, employees = self._extract_raw_company_employees(obj)
                if not company:
                    base = os.path.splitext(fname)[0]
                    company = self._normalize_company_name(base.replace("_report", ""))
                out[company] = employees
                print(f"   loaded raw employees for '{company}': {len(employees)}")
            except Exception as e:
                print(f"âŒ parse error {fname}: {e}")
        self.raw_by_company = out

    def run(self):
        self.load_skills()
        self.load_raw()


# ----------------------------
# Merger (name + company only)
# ----------------------------
class Merger:
    def __init__(self, raw_by_company: Dict[str, List[Dict[str, Any]]],
                 skills_name_by_company: Dict[str, Dict[str, List[str]]]):
        self.raw_by_company = raw_by_company
        self.skills_name_by_company = skills_name_by_company
        self.company_employees: Dict[str, List[Dict[str, Any]]] = {}

    @staticmethod
    def _get(d: Any, path: str, default=None):
        cur = d
        for key in path.split("."):
            if not isinstance(cur, dict) or key not in cur:
                return default
            cur = cur[key]
        return cur

    @staticmethod
    def _norm_name(s: str) -> str:
        return re.sub(r"[^a-z0-9]+", " ", (s or "").lower()).strip()

    def _pick_name(self, emp: Dict[str, Any]) -> str:
        return (
            self._get(emp, "detailed_profile.name")
            or self._get(emp, "basic_info.name")
            or ""
        )

    def _pick_role(self, emp: Dict[str, Any]) -> str:
        role = (
            self._get(emp, "detailed_profile.position")
            or self._get(emp, "basic_info.position")
            or self._get(emp, "detailed_profile.current_company.title")
            or self._get(emp, "basic_info.title")
            or emp.get("role", "")
        )
        if role:
            return role
        exp = self._get(emp, "detailed_profile.experience", [])
        if isinstance(exp, list) and exp:
            return exp[0].get("title", "") or role
        return role

    def _pick_company(self, emp: Dict[str, Any], default_company: str) -> str:
        return (
            self._get(emp, "detailed_profile.current_company.name")
            or self._get(emp, "basic_info.company")
            or default_company
        )

    def _lookup_skills_by_name(self, company: str, name: str) -> List[str]:
        m = self.skills_name_by_company.get(company, {})
        nm = self._norm_name(name)
        return m.get(nm, [])

    def run(self) -> Dict[str, List[Dict[str, Any]]]:
        print("\n=== Merge raw + skills (name+company) ===")
        merged: Dict[str, List[Dict[str, Any]]] = {}
        for company, raw_emps in self.raw_by_company.items():
            rows: List[Dict[str, Any]] = []
            with_skills = 0
            for emp in raw_emps:
                name = self._pick_name(emp)
                role = self._pick_role(emp)
                comp = self._pick_company(emp, company)
                skills = self._lookup_skills_by_name(company, name)
                if skills:
                    with_skills += 1
                rows.append({
                    "name": name,
                    "role": role,
                    "company": comp,
                    "skills": skills
                })
            merged[company] = rows
            print(f"   '{company}': merged {len(rows)} (with skills: {with_skills})")
        self.company_employees = merged
        return merged


# ----------------------------
# Unified Skill Gap Analyzer (consumes Mirage matches)
# ----------------------------
@dataclass
class SkillGap:
    employee_name: str
    role: str
    current_skills: List[str]
    missing_skills: List[str]
    competitor_count: int
    gap_reasoning: str
    confidence_score: float


@dataclass
class Step2Analysis:
    manipal_employee: str
    role: str
    missing_skills: List[str]
    skill_importance: Dict[str, str]
    gap_reasoning: Dict[str, str]
    overall_assessment: str
    recommendations: List[str]
    competitor_companies: List[str]
    competitor_count: int
    evidence_flags: Dict[str, Any]


class UnifiedSkillGapAnalyzer:
    def __init__(self,
                 company_employees: Dict[str, List[Dict[str, Any]]],
                 spectre_matches_path: str,
                 spectre_company_key: str,
                 use_llm: bool,
                 azure_config: Optional[Dict[str, str]] = None):
        self.company_employees = company_employees
        self.spectre_key = (spectre_company_key or "").lower()
        self.use_llm = bool(use_llm)
        self.spectre_matches = self._load_spectre_matches(spectre_matches_path)
        self.employees_by_name = self._build_name_index(company_employees)
        self.client = None
        self.deployment_id = None
        if self.use_llm and azure_config:
            self._setup_azure(azure_config)

    @staticmethod
    def _normalize_name(name: str) -> str:
        return re.sub(r"[^a-z0-9]+", " ", (name or "").lower()).strip()

    @staticmethod
    def _normalize_skill(skill: str) -> str:
        if not skill or not isinstance(skill, str):
            return ""
        s = re.sub(r"[^\w\s+#.]", " ", skill.lower()).strip()
        s = re.sub(r"\s+", " ", s)
        return Config.CUSTOM_SKILL_ALIASES.get(s, s)

    @staticmethod
    def _build_name_index(company_employees: Dict[str, List[Dict[str, Any]]]) -> Dict[str, Dict[str, Dict[str, Any]]]:
        idx = {}
        for company, emps in company_employees.items():
            cmap = {}
            for e in emps:
                key = UnifiedSkillGapAnalyzer._normalize_name(e.get("name", ""))
                if key:
                    cmap[key] = e
            idx[company] = cmap
        return idx


    @staticmethod
    def _load_spectre_matches(path: str) -> Dict[str, List[Dict[str, Any]]]:
        if not os.path.exists(path):
            log.warning(f"spectre_matches not found: {path}, creating mock data")
            # Create basic mock data based on available companies
            return {"competitor_company": []}  # Empty matches for now
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            log.error(f"Failed to load spectre_matches: {e}")
            return {}
        
        
    def _setup_azure(self, cfg: Dict[str, str]):
        try:
            if not AzureOpenAI:
                log.warning("AzureOpenAI SDK not present; disabling LLM.")
                self.client = None
                return
            self.client = AzureOpenAI(
                api_key=(cfg.get("api_key") or os.getenv("AZURE_OPENAI_API_KEY") or "").strip(),
                azure_endpoint=(cfg.get("endpoint") or os.getenv("AZURE_OPENAI_ENDPOINT") or "").strip().rstrip("/"),
                api_version=(cfg.get("api_version") or os.getenv("AZURE_OPENAI_API_VERSION") or "2024-06-01").strip(),
            )
            self.deployment_id = (cfg.get("deployment_id") or os.getenv("AZURE_OPENAI_DEPLOYMENT_ID") or "gpt-4o").strip()
        except Exception as e:
            log.warning(f"Azure init failed, disabling LLM: {e}")
            self.client = None

    def _get_matched_competitors(self, spectre_employee_name: str) -> List[Dict[str, Any]]:
        """
        Crosswalk using Mirage's spectre_matches:
          { "<competitor>": [ { "manipal_name": "...", "matches":[{"name": "...", "similarity": ...}, ...] }, ... ] }
        We map competitor 'name' into company_employees[competitor] by normalized name.
        """
        norm = self._normalize_name(spectre_employee_name)
        out = []
        for company, matches in self.spectre_matches.items():
            lookup = self.employees_by_name.get(company, {})
            for entry in matches or []:
                if self._normalize_name(entry.get("manipal_name", "")) != norm:
                    continue
                for m in entry.get("matches", []) or []:
                    comp_norm = self._normalize_name(m.get("name", ""))
                    if comp_norm in lookup:
                        rec = dict(lookup[comp_norm])
                        rec["company"] = company
                        rec["match_similarity"] = m.get("similarity", 0)
                        out.append(rec)
        return out

    def _calc_gap(self, spectre_emp: Dict[str, Any], comps: List[Dict[str, Any]]) -> Dict[str, Any]:
        cur = {self._normalize_skill(s) for s in (spectre_emp.get("skills", []) or []) if s}
        cur.discard("")
        all_comp: Set[str] = set()
        freq: Dict[str, int] = {}
        for c in comps:
            for s in (c.get("skills", []) or []):
                ns = self._normalize_skill(s)
                if ns:
                    all_comp.add(ns)
                    freq[ns] = freq.get(ns, 0) + 1
        missing = all_comp - cur
        if not comps:
            return {
                "current_skills": sorted(cur),
                "missing_skills": [],
                "competitor_skills": sorted(all_comp),
                "skill_frequency": freq,
                "gap_analysis": "No competitors found for comparison"
            }
        min_freq = max(1, int(round(len(comps) * 0.3)))  # 30% presence threshold
        priority = [s for s in missing if freq.get(s, 0) >= min_freq]
        return {
            "current_skills": sorted(cur),
            "missing_skills": sorted(priority),
            "competitor_skills": sorted(all_comp),
            "skill_frequency": freq,
            "gap_analysis": f"Found {len(priority)} priority gaps from {len(comps)} matched competitors"
        }

    def _llm_reason(self, emp: Dict[str, Any], gap: Dict[str, Any], comps: List[Dict[str, Any]]) -> str:
        if not self.client or not gap.get("missing_skills"):
            return gap.get("gap_analysis", "Analysis complete")
        prompt = (
            "Analyze skill gaps for this employee.\n\n"
            f"EMPLOYEE: {emp.get('name','N/A')}\n"
            f"ROLE: {emp.get('role','N/A')}\n"
            f"CURRENT SKILLS: {gap.get('current_skills', [])}\n"
            f"MISSING SKILLS: {gap.get('missing_skills', [])}\n"
            f"COMPETITORS MATCHED: {len(comps)}\n\n"
            "In 2â€“3 sentences, explain why the missing skills matter for this role "
            "and how this compares with competitor profiles. Be concise."
        )
        try:
            r = self.client.chat.completions.create(
                model=self.deployment_id,
                messages=[{"role": "user", "content": prompt}],
                temperature=Config.LLM_TEMPERATURE,
                max_tokens=Config.LLM_MAX_TOKENS,
            )
            return (r.choices[0].message.content or "").strip()
        except Exception as e:
            return gap.get("gap_analysis", f"LLM reasoning unavailable: {e}")

    def analyze_employee(self, name: str) -> Optional[SkillGap]:
        spectre_map = self.employees_by_name.get(self.spectre_key, {})
        emp = spectre_map.get(self._normalize_name(name))
        if not emp:
            if Config.DEBUG_MODE:
                log.warning(f"Spectre employee not found: {name}")
            return None
        comps = self._get_matched_competitors(name)
        if not comps:
            if Config.DEBUG_MODE:
                log.info(f"No competitor matches for {name}")
            return None
        gap = self._calc_gap(emp, comps)
        # confidence: depends on number of competitors + avg frequency
        if gap["missing_skills"]:
            avg_f = sum(gap["skill_frequency"].get(s, 0) for s in gap["missing_skills"]) / max(1, len(gap["missing_skills"]))
        else:
            avg_f = 0.0
        conf = min(0.95, 0.4 + (len(comps) * 0.1) + (avg_f * 0.2))
        reasoning = self._llm_reason(emp, gap, comps) if self.use_llm else gap["gap_analysis"]
        return SkillGap(
            employee_name=emp.get("name", name),
            role=emp.get("role", ""),
            current_skills=gap["current_skills"],
            missing_skills=gap["missing_skills"],
            competitor_count=len(comps),
            gap_reasoning=reasoning,
            confidence_score=round(conf, 2),
        )

    def analyze_all(self, max_employees: Optional[int] = None) -> List[SkillGap]:
        """
        Only analyze Spectre employees that actually appear in spectre_matches.json
        (i.e., Mirage found matches for them).
        """
        matched_names: Set[str] = set()
        for company, rows in self.spectre_matches.items():
            for row in rows or []:
                if row.get("matches"):
                    matched_names.add(row.get("manipal_name", ""))

        names = list(matched_names)
        if max_employees:
            names = names[:max_employees]

        print(f"Analyzing skill gaps for {len(names)} employees with Mirage matchesâ€¦")
        results: List[SkillGap] = []
        for i, n in enumerate(names, 1):
            if Config.DEBUG_MODE:
                print(f"  [{i}/{len(names)}] {n}")
            g = self.analyze_employee(n)
            if g:
                results.append(g)
        return results

    # ---------- Step 2 (enriched detail) ----------
    def _identify_top_skills(self, gap_data: Dict[str, Any], competitors: List[Dict[str, Any]]) -> List[str]:
        strategic_set = {
            "kubernetes", "microservices", "cloud computing", "distributed systems",
            "ci cd", "docker", "networking", "linux", "aws", "azure", "gcp",
            "python", "java", "javascript", "react", "node js", "spring boot"
        }
        scores = []
        for s in gap_data["missing_skills"]:
            freq = gap_data["skill_frequency"].get(s, 0) / max(1, len(competitors))
            weight = 1.0 if s in strategic_set else 0.7
            scores.append((s, freq * weight, freq))
        scores.sort(key=lambda x: x[1], reverse=True)
        return [s for s, _, __ in scores[:2]]

    def _companies_with_skill(self, skill: str, competitors: List[Dict[str, Any]]) -> List[str]:
        out = set()
        for c in competitors:
            skills = [self._normalize_skill(x) for x in (c.get("skills", []) or [])]
            if skill in skills:
                out.add(c.get("company", "unknown"))
        return sorted(out)

    def _importance_band(self, freq: int, denom: int) -> str:
        if denom <= 0: return "Nice-to-have"
        pct = freq / denom
        if pct >= 0.7: return "Critical"
        if pct >= 0.4: return "Important"
        return "Nice-to-have"

    def generate_detailed(self, gaps: List[SkillGap]) -> List[Step2Analysis]:
        detailed: List[Step2Analysis] = []
        spectre_map = self.employees_by_name.get(self.spectre_key, {})

        for g in gaps:
            emp = spectre_map.get(self._normalize_name(g.employee_name))
            if not emp:
                continue
            comps = self._get_matched_competitors(g.employee_name)
            gap = self._calc_gap(emp, comps)
            top2 = self._identify_top_skills(gap, comps) if gap["missing_skills"] else []

            skill_importance: Dict[str, str] = {}
            gap_reasoning: Dict[str, str] = {}
            for s in g.missing_skills:
                freq = gap["skill_frequency"].get(s, 0)
                band = "Critical" if s in top2 else self._importance_band(freq, len(comps))
                skill_importance[s] = band
                companies = self._companies_with_skill(s, comps)
                gap_reasoning[s] = (
                    f"Present in {freq}/{len(comps)} competitors"
                    + (f"; examples: {', '.join(companies[:3])}" if companies else "")
                )

            recs: List[str] = []
            crit = [s for s, v in skill_importance.items() if v == "Critical"]
            imp = [s for s, v in skill_importance.items() if v == "Important"]
            if crit:
                recs.append(f"ðŸš¨ PRIORITY: Focus on {', '.join(crit[:2])}")
            if imp:
                recs.append(f"ðŸ“ˆ STRATEGIC: Develop {', '.join(imp[:3])}")
            if len(g.missing_skills) > 5:
                recs.append("ðŸŽ¯ FOCUS: Prioritize top 3â€“5 skills for best ROI")

            detailed.append(Step2Analysis(
                manipal_employee=g.employee_name,
                role=g.role,
                missing_skills=g.missing_skills,
                skill_importance=skill_importance,
                gap_reasoning=gap_reasoning,
                overall_assessment=g.gap_reasoning,
                recommendations=recs,
                competitor_companies=sorted({c.get("company","unknown") for c in comps}),
                competitor_count=g.competitor_count,
                evidence_flags={
                    "used_llm": bool(self.client and self.use_llm),
                    "confidence_score": g.confidence_score,
                    "top2_covered": len([s for s in g.missing_skills if s in top2]),
                }
            ))
        return detailed

    # ---------- Export ----------
    @staticmethod
    def export_step1(gaps: List[SkillGap], detailed_path: str, basic_path: Optional[str] = None):
        detailed_payload = [{
            "employee_name": g.employee_name,
            "role": g.role,
            "current_skills": g.current_skills,
            "missing_skills": g.missing_skills,
            "competitor_count": g.competitor_count,
            "gap_reasoning": g.gap_reasoning,
            "confidence_score": g.confidence_score,
        } for g in gaps]
        with open(detailed_path, "w", encoding="utf-8") as f:
            json.dump(detailed_payload, f, indent=2, ensure_ascii=False)
        if basic_path:
            basic_payload = [{"manipal_employee": g.employee_name, "role": g.role, "missing_skills": g.missing_skills} for g in gaps]
            with open(basic_path, "w", encoding="utf-8") as f:
                json.dump(basic_payload, f, indent=2, ensure_ascii=False)
        print(f"Step 1 saved â†’ {detailed_path}" + (f" & {basic_path}" if basic_path else ""))

    @staticmethod
    def export_step2(items: List[Step2Analysis], path: str):
        payload = [{
            "manipal_employee": x.manipal_employee,
            "role": x.role,
            "missing_skills": x.missing_skills,
            "skill_importance": x.skill_importance,
            "gap_reasoning": x.gap_reasoning,
            "overall_assessment": x.overall_assessment,
            "recommendations": x.recommendations,
            "competitor_companies": x.competitor_companies,
            "competitor_count": x.competitor_count,
            "evidence_flags": x.evidence_flags,
        } for x in items]
        with open(path, "w", encoding="utf-8") as f:
            json.dump(payload, f, indent=2, ensure_ascii=False)
        print(f"Step 2 saved â†’ {path}")


# ----------------------------
# Orchestrator adapters
# ----------------------------
async def run(context: Dict[str, Any]) -> Dict[str, Any]:
    """
    Orchestrator entrypoint for Agent 4.
    Expected context["inputs"]:
      {
        "skills_dir": "company_skills",
        "raw_dir": "employee_data",
        "spectre_path": "spectre_matches.json",
        "outputs": {
          "step1_detailed": "...",
          "step1_basic": "...",
          "step2_detailed": "...",
          "final_summary": "..."
        },
        "spectre_company": "xto10x",
        "azure_config": { "api_key": "...", "endpoint": "...", "api_version": "2024-06-01", "deployment_id": "gpt-4o" },
        "use_llm": true,
        "max_employees": null
      }
    """
    inputs = (context or {}).get("inputs", {})
    # Wire config from context (fallback to defaults)
    Config.SKILL_DIR = inputs.get("skills_dir", Config.SKILL_DIR)
    Config.RAW_DIR = inputs.get("raw_dir", Config.RAW_DIR)
    Config.SPECTRE_PATH = inputs.get("spectre_path", Config.SPECTRE_PATH)
    Config.SPECTRE_COMPANY = (inputs.get("spectre_company") or Config.SPECTRE_COMPANY).lower()
    Config.USE_LLM_FOR_SKILLS = bool(inputs.get("use_llm", Config.USE_LLM_FOR_SKILLS))
    max_employees = inputs.get("max_employees", Config.MAX_EMPLOYEES_TO_ANALYZE)

    outs = inputs.get("outputs", {}) or {}
    step1_detailed = outs.get("step1_detailed", Config.STEP1_DETAILED)
    step1_basic    = outs.get("step1_basic", Config.STEP1_BASIC)
    step2_detailed = outs.get("step2_detailed", Config.STEP2_DETAILED)
    final_summary  = outs.get("final_summary", Config.OUTPUT_FILE)

    # Validate + print summary
    Config.validate()
    if Config.DEBUG_MODE:
        Config.print_summary()

    # Load + merge
    loader = DataLoader(Config.SKILL_DIR, Config.RAW_DIR)
    loader.run()
    merger = Merger(loader.raw_by_company, loader.skills_name_by_company)
    company_employees = merger.run()

    if Config.SPECTRE_COMPANY not in company_employees:
        raise RuntimeError(f"Spectre company '{Config.SPECTRE_COMPANY}' not found in merged data.")

    if not os.path.exists(Config.SPECTRE_PATH):
        raise RuntimeError(f"Missing Mirage matches at {Config.SPECTRE_PATH}. Run Agent 2 first.")

    # Analyzer
    analyzer = UnifiedSkillGapAnalyzer(
        company_employees=company_employees,
        spectre_matches_path=Config.SPECTRE_PATH,
        spectre_company_key=Config.SPECTRE_COMPANY,
        use_llm=Config.USE_LLM_FOR_SKILLS,
        azure_config=inputs.get("azure_config"),
    )

    # Step 1
    print("\n=== Step 1: Skill gap analysis ===")
    gaps = analyzer.analyze_all(max_employees=max_employees)
    if not gaps:
        print("âš ï¸ No skill gaps computed (no Mirage matches or skills overlap).")
        gaps = []

    analyzer.export_step1(gaps, detailed_path=step1_detailed, basic_path=step1_basic)

    # Step 2
    print("\n=== Step 2: Detailed analysis ===")
    detailed = analyzer.generate_detailed(gaps)
    analyzer.export_step2(detailed, path=step2_detailed)

    # Final simplified output
    final_payload = [{"manipal_employee": d.manipal_employee, "role": d.role, "missing_skills": d.missing_skills} for d in detailed]
    with open(final_summary, "w", encoding="utf-8") as f:
        json.dump(final_payload, f, indent=2, ensure_ascii=False)
    print(f"\nâœ… Final summary saved â†’ {final_summary}")

    # Attach results to context
    context.setdefault("agents", {})
    context["agents"]["agent4"] = {
        "spectre_company": Config.SPECTRE_COMPANY,
        "files": {
            "step1_detailed": step1_detailed,
            "step1_basic": step1_basic,
            "step2_detailed": step2_detailed,
            "final_summary": final_summary,
        },
        "employees_with_gaps": len([g for g in gaps if g.missing_skills]),
        "timestamp": __import__("datetime").datetime.utcnow().isoformat(),
    }
    return context


def run_sync(context: Dict[str, Any]) -> Dict[str, Any]:
    return asyncio.run(run(context))


# ----------------------------
# CLI
# ----------------------------
if __name__ == "__main__":
    import argparse

    p = argparse.ArgumentParser(description="Agent 4 â€” Unified Skill Gap Analyzer (consumes Mirage matches)")
    p.add_argument("--skills_dir", default=Config.SKILL_DIR)
    p.add_argument("--raw_dir", default=Config.RAW_DIR)
    p.add_argument("--spectre_path", default=Config.SPECTRE_PATH)
    p.add_argument("--spectre_company", default=Config.SPECTRE_COMPANY)
    p.add_argument("--use_llm", action="store_true")
    p.add_argument("--max_employees", type=int, default=None)
    p.add_argument("--step1_detailed", default=Config.STEP1_DETAILED)
    p.add_argument("--step1_basic", default=Config.STEP1_BASIC)
    p.add_argument("--step2_detailed", default=Config.STEP2_DETAILED)
    p.add_argument("--final_summary", default=Config.OUTPUT_FILE)
    args = p.parse_args()

    ctx = {
        "inputs": {
            "skills_dir": args.skills_dir,
            "raw_dir": args.raw_dir,
            "spectre_path": args.spectre_path,
            "spectre_company": args.spectre_company.lower(),
            "use_llm": bool(args.use_llm),
            "max_employees": args.max_employees,
            "outputs": {
                "step1_detailed": args.step1_detailed,
                "step1_basic": args.step1_basic,
                "step2_detailed": args.step2_detailed,
                "final_summary": args.final_summary,
            },
            # Optionally pass azure_config; otherwise env vars will be used if present
            # "azure_config": {
            #     "api_key": os.getenv("AZURE_OPENAI_API_KEY"),
            #     "endpoint": os.getenv("AZURE_OPENAI_ENDPOINT"),
            #     "api_version": os.getenv("AZURE_OPENAI_API_VERSION", "2024-06-01"),
            #     "deployment_id": os.getenv("AZURE_OPENAI_DEPLOYMENT_ID", "gpt-4o"),
            # },
        }
    }
    run_sync(ctx)
